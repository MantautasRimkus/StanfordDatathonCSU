---
header-includes:
   - \usepackage{bm}
   - \usepackage{float}
   - \floatplacement{figure}{H}
   - \usepackage{booktabs}
   - \usepackage{sectsty} \sectionfont{\centering \emph}
output:
  pdf_document: default
  html_document: default
  word_document: default
 
---
\newcommand\btheta{\mbox{\boldmath${\theta}$}}

```{r setup, include=FALSE}
# Use echo = FALSE for Answer Key without R code, 
# echo = TRUE for complete solutions.
knitr::opts_chunk$set(echo = TRUE)
library(plyr)
library("tidyverse")
library("xtable")
library("Rcpp")
library("plyr")
library("knitr")
```

Team No: 202

Track No.: 2. 

# Our name of the project

Link to GitHub Repository: https://github.com/MantautasRimkus/StanfordDatathonCSU


### Plan

* Write introduction: About Covid, about anxiety, about how 19-28 more(no more?) prone to it. Write that our analysis shows that a lot of 18-29 are in the college. 

* Write introduction: calculate (using historical data) how many 18-29 is in college. Maybe prediction for 2020. 
* Describe data sources used in this research:
   - Anxiety
   - Covid
   - Google

* Overview trends in anxiety data (functional analysis)

* Panel modelling 

* Discussion/results. 

## Predicting Anxiety from COVID Cases Using a Panel Model

We are searching for a way for school administrators to anticipate increased anxiety among their students. In 2020 and today, anecdotally, COVID is a significant source of anxiety. We used a panel model to find the predictiveness of covid cases on anxiety in 18-29 year olds.

Panel models are used for regression when the response and predictor variables are longitudinal. In this case, we treat US states as entities and have longitudinal values for both anxiety and new COVID cases.

For states $s=1,\dots, 50$ and time periods $t=1,\dots,T$, we use the model

$$
\mbox{anx}_{s,t} = \alpha_s + \beta_1 \mbox{anx}_{s,t-1} + \beta_2 \mbox{COVID}_{s,t} + \varepsilon_{s,t}
$$

This model allows for state-specific intercepts ($\alpha_s$), autocorrelation in anxiety within a state ($\beta_1$), and an effect of COVID cases on anxiety ($\beta_1$).

Alternatively, we can have a random effect for the state-specific intercepts,
\begin{align*}
\mbox{anx}_{s,t} &= \alpha + a_s + \beta_1 \mbox{anx}_{s,t-1} + \beta_2 \mbox{COVID}_{s,t} + \varepsilon_{s,t} \\
a_s &\sim N(0, \sigma^2_a)
\end{align*}

The `plm` package in `R` allows us to fit both of these models and perform a hypothesis test to determine which fits our data better.

Because COVID cases can vary largely by state due to the size of the state, we were careful in how we constructed the $\mbox{COVID}_{s,t}$ covariate. We used the log ratio of new cases in sequential weeks as the COVID covariate:
$$\mbox{COVID}_{s,t} = \log\left(\frac{\text{New cases in state $s$ and week $t$}}{\text{New cases in state $s$ and week $t-1$}}\right).$$

This value is appealing for three reasons. First, it places all states on the same scale by only considering the ratio of subsequent weeks. Second, by using a ratio of new covid cases it handles the exponential growth nature of the pandemic. And third, it works well with an autoregressive model. A positive value means the pandemic is currently accelerating in a state, possibly resulting in increasing anxiety relative to week $t-1$. Similarly, a negative value means the pandemic is slowing down, possibly resulting in decreasing anxiety relative to week $t-1$.

### Results

```{r getmodeldata, include=FALSE}
library(plm)

# Read in anxiety data, covid data (whole US) and covid data (by state)
anxiety <- read.csv("anx_rate_ext.csv")
covid.us <- read.csv("covid-data/weekly-us.csv")
covid <- read.csv("covid-data/weekly-states.csv")

# Create logitudinal long form data frame
paneldata <- data.frame(
  State = covid$State,
  Date = covid$EndofWeek,
  CasesPerDay = covid$Cases,
  LogCasesRatio = covid$LogRatio
)
for (i in 1:nrow(paneldata)) {
  s <- paneldata[i, "State"]
  d <- paneldata[i, "Date"]
  
  if (d %in% anxiety$date_end) {
    paneldata[i,"anx"] <- anxiety[anxiety$date_end == d, s]
  }
}

paneldata <- paneldata[paneldata$Date %in% anxiety$date_end,] # Only dates with an anxiety measurement
```

First, we have the output from the fixed effects model:
```{r runfixedmodel}
# Model: panel model by state with anxiety as response regressed on covid
fit.states.fixed <- plm(anx ~ LogCasesRatio + lag(anx), paneldata, 
                        index=c("State", "Date"), model="within")
summary(fit.states.fixed)
```

We can see that both the lagged anxiety variable and LogCasesRatio are significant predictors. The value of the coefficient with $\mbox{COVID}_{s,t}$ shows that if new cases were to double from one week to the next, we expect our response anxiety odds to increase by `r round(fit.states.fixed$coefficients[1] * log(2), digits=4)`.

The `plm` package also allows us to run a Hausman hypothesis test to see whether a fixed effects or random effects model is a better fit for our data.

```{r runrandommodel}
fit.states.random <- plm(anx ~ LogCasesRatio + lag(anx), paneldata, 
                         index=c("State", "Date"), model="random")
phtest(fit.states.fixed, fit.states.random)
```

The small p-value indicates that the null hypothesis of a random effects model should be rejected, and so our results from the fixed effects model are a better fit.